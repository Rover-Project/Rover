# üß™ Scripts de Teste Simplificados - MediaPipe

Pasta com scripts simplificados para teste inicial dos modelos MediaPipe em segmentos espec√≠ficos:
- **Detec√ß√£o de Gestos** (Gesture Recognition)
- **Mapeamento de M√£os** (Hand Landmarks)
- **Detec√ß√£o de Objetos** (Object Detection)

## üìã Pr√©-requisitos

### Arquivos de Modelo Necess√°rios

Os scripts requerem os seguintes arquivos `.task` nesta pasta:

```
tests/
‚îú‚îÄ‚îÄ gesture_recognizer.task      # Modelo para reconhecimento de gestos
‚îú‚îÄ‚îÄ hand_landmarker.task         # Modelo para mapeamento de pontos de m√£o
‚îú‚îÄ‚îÄ test_gesture_recognition.py
‚îú‚îÄ‚îÄ test_hand_landmarks.py
‚îú‚îÄ‚îÄ test_object_detection.py
‚îî‚îÄ‚îÄ requirements.txt
```

**Para baixar os modelos**, acesse:
- [MediaPipe Model Hub](https://developers.google.com/mediapipe/solutions/model_hub)
- Ou use os modelos j√° na pasta se j√° foram baixados

### Instala√ß√£o de Depend√™ncias

```bash
# Navegue at√© a pasta tests
cd Rover/tests

# Instale as depend√™ncias
pip install -r requirements.txt
```

## üéØ Scripts de Teste

### 1. Reconhecimento de Gestos
**Arquivo:** `test_gesture_recognition.py`

Detecta gestos das m√£os em tempo real:
- Thumbs Up (Polegar para cima)
- Thumbs Down (Polegar para baixo)
- Pointing Up (Apontando para cima)
- Victory (Sinal de vit√≥ria)
- Open Palm (Palma aberta)
- Closed Fist (Punho fechado)

**Uso:**
```bash
python test_gesture_recognition.py
# ou com c√¢mera espec√≠fica
python test_gesture_recognition.py --camera-id 0
```

**Controles:**
- `q` - Sair
- `s` - Capturar screenshot

**Sa√≠da:**
- Mostra o gesto detectado com confian√ßa (0-1)
- Exibe FPS em tempo real
- Salva screenshots ao pressionar `s`

---

### 2. Mapeamento de Pontos de M√£o
**Arquivo:** `test_hand_landmarks.py`

Detecta os 21 pontos de refer√™ncia (landmarks) das m√£os:
- Pulso (wrist)
- Palma (palm)
- Dedos e articula√ß√µes

**Uso:**
```bash
python test_hand_landmarks.py
# ou com m√∫ltiplos par√¢metros
python test_hand_landmarks.py --camera-id 0 --num-hands 2
```

**Par√¢metros:**
- `--camera-id` - ID da c√¢mera (padr√£o: 0)
- `--num-hands` - N√∫mero m√°ximo de m√£os a detectar (padr√£o: 2)

**Controles:**
- `q` - Sair
- `s` - Capturar screenshot

**Sa√≠da:**
- Desenha os 21 pontos de refer√™ncia por m√£o
- Mostra conex√µes entre pontos
- Identifica se √© m√£o esquerda ou direita com confian√ßa
- Exibe FPS em tempo real

---

### 3. Detec√ß√£o de Objetos
**Arquivo:** `test_object_detection.py`

Detecta objetos por segmenta√ß√£o de cor HSV + forma (c√≠rculos):

**Cores suportadas:**
- `red` - Vermelho (padr√£o)
- `blue` - Azul
- `green` - Verde
- `yellow` - Amarelo

**Uso:**
```bash
python test_object_detection.py
# ou com par√¢metros customizados
python test_object_detection.py --camera-id 0 --color red --min-radius 10 --max-radius 200
```

**Par√¢metros:**
- `--camera-id` - ID da c√¢mera (padr√£o: 0)
- `--color` - Cor do objeto (padr√£o: red)
- `--min-radius` - Raio m√≠nimo em pixels (padr√£o: 10)
- `--max-radius` - Raio m√°ximo em pixels (padr√£o: 200)

**Controles:**
- `q` - Sair
- `s` - Capturar screenshot
- `c` - Ativar/desativar modo calibra√ß√£o (mostra valores HSV)

**Sa√≠da:**
- Detecta c√≠rculos na imagem
- Mostra duas janelas:
  - Detec√ß√£o (com c√≠rculos desenhados)
  - M√°scara HSV (para visualizar a segmenta√ß√£o)
- Exibe raio e posi√ß√£o dos objetos detectados
- FPS em tempo real

---

## üîß Modo Calibra√ß√£o (Detec√ß√£o de Objetos)

Se o script n√£o detectar bem sua cor, use o modo calibra√ß√£o:

```bash
python test_object_detection.py --color red
# Pressione 'c' durante a execu√ß√£o para ativar modo calibra√ß√£o
```

**No modo calibra√ß√£o:**
- Um c√≠rculo aparecer√° no centro da tela
- Alinhe o objeto com o c√≠rculo
- Veja os valores HSV do pixel central
- Ajuste os intervalos em `COLOR_RANGES` se necess√°rio

**Exemplo de ajuste:**
```python
'red': [
    ((0, 100, 100), (10, 255, 255)),      # Vermelho inferior
    ((160, 100, 100), (180, 255, 255))    # Vermelho superior
]
```

---

## üìä Estrutura dos Scripts

Todos os scripts seguem o padr√£o:

```python
class [Nome]Test:
    def __init__(self, ...):
        # Inicializa configura√ß√µes
        
    def _load_model(self):
        # Carrega modelo .task
        
    def run(self):
        # Loop principal de captura/processamento
        
def main():
    # Parse de argumentos CLI
```

---

## üêõ Troubleshooting

### C√¢mera n√£o abre
```bash
# Teste qual ID usar
python -c "import cv2; cap = cv2.VideoCapture(1); print('OK' if cap.isOpened() else 'FAIL')"
# Tente --camera-id 0, 1, 2, etc
```

### Modelos n√£o encontrados
Garanta que est√£o na pasta `tests/`:
```bash
ls -la *.task
# Deve exibir:
# gesture_recognizer.task
# hand_landmarker.task
```

### Baixo FPS / Lag
- Reduza a resolu√ß√£o da c√¢mera
- Feche outras aplica√ß√µes
- Teste em m√°quina com melhor GPU

### Detec√ß√£o imprecisa (Gestos/Landmarks)
- Teste em boa ilumina√ß√£o
- Use fundo simples
- Aumentar confian√ßa √© feito nos par√¢metros do modelo

### Detec√ß√£o de objetos imprecisa
1. Use modo calibra√ß√£o (`c`)
2. Ajuste cores em `COLOR_RANGES`
3. Varie `--min-radius` e `--max-radius`
4. Melhore a ilumina√ß√£o

---

## üìù Logs e Sa√≠da

Os scripts exibem:
- ‚úì Status de inicializa√ß√£o
- ‚úì FPS em tempo real
- ‚úì Detec√ß√µes com confian√ßa
- ‚úì Mensagens de captura de screenshot
- ‚úì Mensagens de erro se houver

---

## üöÄ Pr√≥ximos Passos

Ap√≥s validar os modelos com estes scripts:

1. **Integrar ao Rover:** Use as classes em `rover_lib/modules/vision/`
2. **Controlar movimentos:** Mapear gestos para comandos do rover
3. **Processar em tempo real:** Executar em Raspberry Pi com camera module

---

## üìö Refer√™ncias

- [MediaPipe Official Docs](https://developers.google.com/mediapipe)
- [MediaPipe Solutions](https://developers.google.com/mediapipe/solutions)
- [OpenCV Documentation](https://docs.opencv.org/)

